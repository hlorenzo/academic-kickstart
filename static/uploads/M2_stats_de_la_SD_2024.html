<!DOCTYPE html>
<html lang="en"><head>
<script src="M2_stats_de_la_SD_2024_files/libs/clipboard/clipboard.min.js"></script>
<script src="M2_stats_de_la_SD_2024_files/libs/quarto-html/tabby.min.js"></script>
<script src="M2_stats_de_la_SD_2024_files/libs/quarto-html/popper.min.js"></script>
<script src="M2_stats_de_la_SD_2024_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="M2_stats_de_la_SD_2024_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="M2_stats_de_la_SD_2024_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="M2_stats_de_la_SD_2024_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="M2_stats_de_la_SD_2024_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.553">

  <meta name="author" content="Hadrien Lorenzo, Aix Marseille Université">
  <title>Données Manquantes</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="M2_stats_de_la_SD_2024_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="M2_stats_de_la_SD_2024_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="M2_stats_de_la_SD_2024_files/libs/revealjs/dist/theme/quarto.css">
  <link href="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Données Manquantes</h1>
  <p class="subtitle">M2 Stats de la SD, 2024-2025</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Hadrien Lorenzo, Aix Marseille Université 
</div>
</div>
</div>

</section>
<section>
<section id="introduction" class="title-slide slide level1 center">
<h1>Introduction</h1>
<div class="cell">
<style type="text/css">
div.callout{font-size:1.6rem !important}.reveal strong{color:#1F63DE}.reveal h1{color:#009A74}.reveal h2{color:#009A74}.reveal h2 strong{color:inherit}.reveal h3{font-size:2rem !important;color:black}.reveal a{color:black;text-decoration:underline}.callout-title strong{color:inherit;font-size:2rem !important}.sourceCode{font-size:1.3rem !important}
</style>
</div>
</section>
<section id="définition-et-analyse-cas-complet" class="slide level2">
<h2>Définition et analyse cas complet</h2>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Définition</strong></p>
</div>
<div class="callout-content">
<p>On dit qu’une donnée est manquante lorsque l’observation d’une variable pour une observation n’est pas accessible</p>
</div>
</div>
</div>
<p>On peut choisir de retirer l’observation associée aux NA mais peu indiqué si :</p>
<ul>
<li>petit échantillon (<span class="math inline">\(n\)</span> faible),</li>
<li>grande quantité de NA.</li>
</ul>
<p>On peut aussi retirer les variables associées aux NA si :</p>
<ul>
<li>la structure des données le permet (<span class="math inline">\(p\)</span> important)</li>
<li><strong>et</strong> peu de variables sont atteintes par des NA</li>
</ul>
<p>Le jeu de données résultant est appelé <strong>cas complet</strong>, en pratique il n’est jamais conseillé d’utiliser cette approche… Pourquoi ?</p>
</section>
<section id="exemple" class="slide level2">
<h2>Exemple</h2>
<p>Soit le jeu de données : <span class="math inline">\(n=100\)</span> personnes à qui on a demandé de renseigner leur taille et leur poids… plusieurs problèmes peuvent se produire!</p>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-2-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"></section>
<section id="pas-plus-de-20-pesées" class="slide level2">
<h2>… pas plus de 20 pesées…</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-3-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"></section>
<section id="saturation-à-70kg" class="slide level2">
<h2>… saturation à 70kg…</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-4-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"></section>
<section id="certains-ne-répondent-pas" class="slide level2">
<h2>… certains ne répondent pas…</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-5-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"><div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Attention, une sous-population semble ne pas répondre…</strong></p>
</div>
<div class="callout-content">
<p>… il n’y a aucun moyen de voir qu’il y a une structure de données manquantes ici!</p>
</div>
</div>
</div>
</section>
<section id="en-résumé-lanalyse-cas-complet-nest-pas-conseillée" class="slide level2">
<h2>En résumé, l’analyse <strong>cas complet</strong> n’est pas conseillée</h2>
<ul>
<li>Peut introduire un biais dans l’estimation des paramètres,</li>
</ul>
<p><br>
</p>
<ul>
<li>Peut réduire la puissance des tests statistiques en augmentant les écart-types des estimateurs,</li>
</ul>
<p><br>
</p>
<ul>
<li>…</li>
</ul>
</section>
<section id="solutions-restantes-1" class="slide level2">
<h2>Solutions restantes (1)</h2>
<p>Il reste de remplir les cases, c’est l’<strong>imputation</strong>.</p>
<ul>
<li>Estimer les NA avec des valeurs fixées (<strong>Imputation simple</strong>) :
<ul>
<li>Conditionnellement à la seule variable considérée :
<ul>
<li><strong>moyenne/médiane</strong>,</li>
<li><strong>Last Observation Carried Forward</strong> (<strong>LOCF</strong>),</li>
</ul></li>
<li>Sur l’ensemble des variables :
<ul>
<li>k-plus proches voisins (<strong>kNN</strong> via ),</li>
<li>forêts aléatoires (<strong>missForest</strong> <span class="citation" data-cites="mimi">(<a href="#/références" role="doc-biblioref" onclick="">Stekhoven and Buehlmann 2012</a>)</span>, itératif),</li>
<li>PCA (<strong>missMDA</strong> <span class="citation" data-cites="missmda">(<a href="#/références" role="doc-biblioref" onclick="">Josse and Husson 2016</a>)</span>, itératif),</li>
<li>…</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="solutions-restantes-2" class="slide level2">
<h2>Solutions restantes (2)</h2>
<ul>
<li><strong>Imputation multiple</strong> :
<ul>
<li>Modèles conditionnels (<strong>mice</strong> <span class="citation" data-cites="mice">(<a href="#/références" role="doc-biblioref" onclick="">van Buuren and Groothuis-Oudshoorn 2011</a>)</span> )</li>
<li>PCA (<strong>missMDA</strong>)</li>
<li>…</li>
</ul></li>
</ul>
<p>Voir le CRAN Task View assez complet <a href="https://cran.r-project.org/web/views/MissingData.html"></a><sup>1</sup></p>
<aside><ol class="aside-footnotes"><li id="fn1"><p><a href="https://cran.r-project.org/web/views/MissingData.html" class="uri">https://cran.r-project.org/web/views/MissingData.html</a></p></li></ol></aside></section></section>
<section>
<section id="mécanismes" class="title-slide slide level1 center">
<h1>Mécanismes</h1>

</section>
<section id="une-classification-des-processus-de-perte-de-données" class="slide level2">
<h2>Une classification des processus de perte de données</h2>
<p><br>
</p>
<p>Due à <span class="citation" data-cites="little2019statistical">Little and Rubin (<a href="#/références" role="doc-biblioref" onclick="">1976</a>)</span> :</p>
<ul>
<li><strong>MCAR</strong> (<em>Missing Completely At Random</em>), si la probabilité que la donnée soit manquante ne dépend pas de cette valeur ni des données observées</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>MAR</strong> (<em>Missing At Random</em>), si la probabilité que la donnée soit manquante ne dépend pas de cette valeur, conditionellement aux données observées</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>MNAR</strong> (<em>Missing Not At Random</em>), si la probabilité que la donnée soit manquante dépend de cette valeur, conditionellement aux données observées</li>
</ul>
<p><br>
</p>
</section>
<section id="exemples" class="slide level2">
<h2>Exemples</h2>
<p><br>
</p>
<ul>
<li><strong>MCAR</strong> Un capteur qui s’éteind et se rallume sans raison. Un patient malade qui se rend à l’hopital seulement lorsqu’il reçoit du courrier.</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>MAR</strong> Un étudiant ne se rend pas à un examen de rattrapage puisqu’il a réussi l’examen normal.</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>MNAR</strong> Qui gagne bien sa vie répond moins facilement à toute question sur son salaire.</li>
</ul>
<p><br>
</p>
</section>
<section id="autre-façon-de-le-dire-1" class="slide level2">
<h2>Autre façon de le dire (1)</h2>
<p>On qualifie le mécanisme dee perte de données en fonction de la probabilité de la perte de données conditionnellement aux données observées ou non observées :</p>
<p><br>
</p>
<ul>
<li><strong>MCAR</strong> si la probabilité de manquement <em>est indépendante</em> des données manquantes et observées,</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>MAR</strong> si la probabilité de manquement <em>est indépendante</em> de la donnée manquante, conditionnellement aux données observées,</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>MNAR</strong> si la probabilité de manquement <em>n’est pas indépendante</em> de la donnée manquante, conditionnellement aux données observées.</li>
</ul>
<p><br>
</p>
</section>
<section id="autre-façon-de-le-dire-2" class="slide level2">
<h2>Autre façon de le dire (2)</h2>
<p>Si on note <span class="math inline">\(M\)</span> la matrice indicatrice des données manquantes telle que</p>
<p><span class="math display">\[
m_{i,j} = \left\{
\begin{array}{cl}
1 &amp; \text{si la donnée $x_{i,j}$ est manquante} \\
0 &amp; \text{sinon}
\end{array}\right.
\]</span> pour l’individu <span class="math inline">\(i\)</span> et la variable <span class="math inline">\(j\)</span>.</p>
<p>Avec aussi, <span class="math inline">\(X^{(o)}\)</span> les données observées et <span class="math inline">\(X^{(m)}\)</span> les données manquantes, alors</p>
<p><br>
</p>
<ul>
<li>Si <span class="math inline">\(\mathbb{P}(M|X^{(o)},X^{(m)}) = \mathbb{P}(M)\)</span>, alors c’est un mécanisme <strong>MCAR</strong>,</li>
</ul>
<p><br>
</p>
<ul>
<li>Si <span class="math inline">\(\mathbb{P}(M|X^{(o)},X^{(m)}) = \mathbb{P}(M|X^{(o)})\)</span>, alors c’est un mécanisme <strong>MAR</strong>,</li>
</ul>
<p><br>
</p>
<ul>
<li>Si <span class="math inline">\(\mathbb{P}(M|X^{(o)},X^{(m)}) \neq \mathbb{P}(M|X^{(o)})\)</span>, alors c’est un mécanisme <strong>MNAR</strong>.</li>
</ul>
</section>
<section id="commentaires" class="slide level2">
<h2>Commentaires</h2>
<p><br>
</p>
<ul>
<li><strong>MCAR</strong> Le plus “simple” à gérer, mais peu réaliste</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>MAR</strong> Peut aussi être géré si approche multivariée</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>MNAR</strong> On s’en rend compte après coup car rien ne permet de le savoir dans les données</li>
</ul>
</section>
<section id="exemple-lâge-de-la-population-française-selon-linsee-1" class="slide level2">
<h2>Exemple, l’âge de la population française selon l’Insee (1)</h2>
<p>On peut télécharger ces données sur le site de l’<a href="https://www.insee.fr/fr/statistiques/2381474#figure1_radio1">Insee</a><sup>1</sup>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href=""></a>insee <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"files/insee.csv"</span>, <span class="at">sep=</span><span class="st">";"</span>)[<span class="sc">-</span><span class="dv">15</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb1-2"><a href=""></a>prop <span class="ot">&lt;-</span> insee<span class="sc">$</span>Ensemble<span class="sc">/</span><span class="fu">sum</span>(insee<span class="sc">$</span>Ensemble)<span class="sc">*</span><span class="dv">100</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-7-1.png" class="quarto-figure quarto-figure-center" width="691"></p>
</figure>
</div>
</div>
</div>
<aside><ol class="aside-footnotes"><li id="fn2"><p><a href="https://www.insee.fr/fr/statistiques/2381474#figure1_radio1" class="uri">https://www.insee.fr/fr/statistiques/2381474#figure1_radio1</a></p></li></ol></aside></section>
<section id="exemple-lâge-de-la-population-française-selon-linsee-2" class="slide level2">
<h2>Exemple, l’âge de la population française selon l’Insee (2)</h2>
<h3 id="exercice">Exercice</h3>
<p>Vous créez un jeu de données de taille <span class="math inline">\(n=\)</span> 1000 formé par deux variables :</p>
<ul>
<li><strong>age</strong> (variable continue positive) à partir de la distribution de l’Insee,</li>
<li><strong>a_moins_de_15_ans</strong> (1 si oui, 0 sinon) à partir de la variable <strong>age</strong></li>
</ul>
<p>A partir de ce jeu de données, vous allez simuler trois scénarios de données manquantes :</p>
<ul>
<li>Sc<span class="math inline">\(_1\)</span> : “10<span class="math inline">\(\%\)</span> des gens refusent de donner leur âge.”</li>
<li>Sc<span class="math inline">\(_2\)</span> : “Un bug informatique a supprimé les âges des moins de 15 ans.”</li>
<li>Sc<span class="math inline">\(_3\)</span> : “C’est vendredi, les étudiants ne sont pas là!”</li>
</ul>
<p>Vous discuterez des hypothèses prises et des résultats obtenus.</p>
</section>
<section id="sc_1-10-des-gens-refusent-de-donner-leur-âge." class="slide level2">
<h2>Sc<span class="math inline">\(_1\)</span> : “10<span class="math inline">\(\%\)</span> des gens refusent de donner leur âge.”</h2>
<p>10<span class="math inline">\(\%\)</span> des observations sont à retirer du jeu de données</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href=""></a>prop_no_NA <span class="ot">&lt;-</span> <span class="fl">0.9</span></span>
<span id="cb2-2"><a href=""></a>sampSC1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(prop),<span class="at">size =</span> prop_no_NA<span class="sc">*</span>n_pop,<span class="at">prob =</span> prop,<span class="at">replace =</span> T)</span>
<span id="cb2-3"><a href=""></a>propSC1 <span class="ot">&lt;-</span> <span class="fu">table</span>(sampSC1)<span class="sc">/</span>(prop_no_NA<span class="sc">*</span>n_pop)<span class="sc">*</span><span class="dv">100</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-9-1.png" class="quarto-figure quarto-figure-center r-stretch" width="777"></section>
<section id="sc_2-suppression-des-âges-des-moins-de-15-ans." class="slide level2">
<h2>Sc<span class="math inline">\(_2\)</span> : “Suppression des âges des moins de 15 ans.”</h2>
<p>Les individus de classe <strong>1</strong> sont à retirer du jeu de données (hyp 1)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href=""></a>propSC2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(prop),<span class="at">size =</span> n_pop,<span class="at">prob =</span> prop,<span class="at">replace =</span> T)</span>
<span id="cb3-2"><a href=""></a>class1 <span class="ot">&lt;-</span> <span class="fu">which</span>(propSC2<span class="sc">==</span><span class="dv">1</span>) ; class1_no15 <span class="ot">&lt;-</span> class1[<span class="dv">1</span><span class="sc">:</span>(<span class="fu">length</span>(class1))] ; propSC2[class1_no15] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb3-3"><a href=""></a>propSC2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">table</span>(propSC2)<span class="sc">/</span>n_pop<span class="sc">*</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-11-1.png" class="quarto-figure quarto-figure-center r-stretch" width="777"></section>
<section id="sc_3-cest-vendredi-les-étudiants-ne-sont-pas-là" class="slide level2">
<h2>Sc<span class="math inline">\(_3\)</span> : “C’est vendredi, les étudiants ne sont pas là!”</h2>
<p>La moitié des individus de classe <strong>3</strong> est à retirer du jeu de données (hyp 2)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href=""></a>propSC3 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(prop),<span class="at">size =</span> n_pop,<span class="at">prob =</span> prop,<span class="at">replace =</span> T)</span>
<span id="cb4-2"><a href=""></a>class1 <span class="ot">&lt;-</span> <span class="fu">which</span>(propSC3<span class="sc">==</span><span class="dv">3</span>);class1_stu <span class="ot">&lt;-</span> class1[<span class="dv">1</span><span class="sc">:</span>(<span class="fu">length</span>(class1)<span class="sc">/</span><span class="dv">2</span>)];propSC3[class1_stu] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb4-3"><a href=""></a>propSC3 <span class="ot">&lt;-</span> <span class="fu">table</span>(propSC3)<span class="sc">/</span>n_pop<span class="sc">*</span><span class="dv">100</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-13-1.png" class="quarto-figure quarto-figure-center r-stretch" width="777"></section>
<section id="exemple-lâge-de-la-population-française-selon-linsee-commentaires" class="slide level2">
<h2>Exemple, l’âge de la population française selon l’Insee, commentaires</h2>
<ul>
<li><p>Sc<span class="math inline">\(_1\)</span> : On reconnaît l’hypothèse <strong>MCAR</strong></p></li>
<li><p>Sc<span class="math inline">\(_2\)</span> peut être géré conditionellement à la variable indicatrice : <strong>MAR</strong></p></li>
<li><p>Sc<span class="math inline">\(_3\)</span> est plus difficile à gérer : <strong>MNAR</strong></p></li>
</ul>
<p><br>
</p>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Une solution pour le cas MNAR ?</strong></p>
</div>
<div class="callout-content">
<p>Rechercher des informations supplémentaires via une autre variable par exemple ou un autre essai similaire ou l’expérience d’un expert</p>
</div>
</div>
</div>
<p><br>
</p>
</section></section>
<section>
<section id="régression-et-imputation" class="title-slide slide level1 center">
<h1>Régression et imputation</h1>

</section>
<section id="modèle-linéaire-simple-à-une-covariable" class="slide level2">
<h2>Modèle linéaire simple à une covariable</h2>
<p>On considère le modèle suivant :</p>
<p><span class="math display">\[
  \left[y|x,\alpha,\beta,\sigma^2\right] ~\sim \mathcal{N}(\alpha + \beta x,\sigma^2),
\]</span> où <span class="math inline">\(x\)</span> est la covariable, <span class="math inline">\(\alpha\)</span> l’ordonnée à l’origine, <span class="math inline">\(\beta\)</span> la pente et <span class="math inline">\(\sigma^2\)</span> la variance du bruit additif. C’est le modèle linéaire très classique.</p>
<p>Ici <span class="math inline">\(\theta=(\alpha,\beta,\sigma^2)\)</span> et des données manquantes apparaîssent dans <span class="math inline">\(y\)</span>.</p>
<p>La problématique ressemble à un problème d’estimation de paramètres dans un modèle linéaire simple, mais avec des données manquantes.</p>
</section>
<section id="simulation-des-données" class="slide level2">
<h2>Simulation des données</h2>
<p>Soit le modèle de simulation</p>
<p><span class="math display">\[
y = x + \epsilon
\]</span> où <span class="math inline">\(x \sim \mathcal{N}(0,1)\)</span>, <span class="math inline">\(\epsilon \sim \mathcal{N}(0,1/4)\)</span> et <span class="math inline">\(\epsilon \perp \!\!\! \perp x\)</span>. Donc <span class="math inline">\(\alpha=0\)</span>, <span class="math inline">\(\beta=1\)</span> et <span class="math inline">\(\sigma^2=1/4\)</span>. On a accès à :</p>
<ul>
<li>un échantillon d’entraînement <span class="math inline">\(S=(x_i,y_i)_{i=1,\dots, n}\)</span> de taille <span class="math inline">\(n=\)</span> 50,</li>
<li>un échantillon de test <span class="math inline">\(\tilde{S}=(x_i)_{i=n+1,\dots,n+\tilde{n}}\)</span> de taille <span class="math inline">\(\tilde{n}=\)</span> 30.</li>
</ul>
<p>En régression, on réalise deux opérations successives :</p>
<ul>
<li>construction d’un modèle de régression sur <span class="math inline">\(S\)</span>, noté <span class="math inline">\(\mathcal{P}\)</span>,</li>
<li>estimation de la réponse de <span class="math inline">\(\mathcal{P}\)</span> à une covariable <span class="math inline">\(x_0\)</span>, notée <span class="math inline">\(\hat{y_0}=\mathcal{P}(x_0)\)</span>.</li>
</ul>
</section>
<section id="lien-avec-les-données-manquantes" class="slide level2">
<h2>Lien avec les données manquantes</h2>
<p>En combinant <span class="math inline">\(S\)</span> et <span class="math inline">\(\tilde{S}\)</span>, on a accès à un jeu de données de dimensions <span class="math inline">\((n+\tilde{n})\times(2)\)</span> avec <span class="math inline">\(\tilde{n}\)</span> données manquantes : les valeurs <span class="math inline">\((y_i)_{i=n+1,\dots,n+\tilde{n}}\)</span>.</p>
<p>On peut observer la structure des données manquantes grâce aux commandes suivantes</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href=""></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)  ;  y <span class="ot">&lt;-</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,sigma)</span>
<span id="cb5-2"><a href=""></a>x_t <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_tilde,<span class="dv">0</span>,<span class="dv">1</span>)  ;  y_t <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n_tilde)</span>
<span id="cb5-3"><a href=""></a>pattern_miss <span class="ot">&lt;-</span> <span class="fu">md.pattern</span>(<span class="fu">rbind</span>( <span class="fu">cbind</span>(x,y) , <span class="fu">cbind</span>(x_t,y_t) ))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-14-1.png" class="quarto-figure quarto-figure-center r-stretch" width="216"></section>
<section id="analyse-du-jeu-de-données-simulées" class="slide level2">
<h2>Analyse du jeu de données simulées</h2>
<p>Comparaison de 2 méthodologies d’imputation :</p>
<ul>
<li>à la moyenne,</li>
<li>en utilisant le modèle de régression linéaire.</li>
</ul>
<p>Dans chaque cas on observera attentivement le comportement des distributions après imputations.</p>
</section>
<section id="après-imputation-dune-observation" class="slide level2">
<h2>Après imputation d’une observation</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-15-1.png" class="quarto-figure quarto-figure-center r-stretch" width="432"></section>
<section id="après-imputation-de-5-observations" class="slide level2">
<h2>Après imputation de 5 observations</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-16-1.png" class="quarto-figure quarto-figure-center r-stretch" width="432"></section>
<section id="après-imputation-de-30-observations" class="slide level2">
<h2>Après imputation de 30 observations</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-17-1.png" class="quarto-figure quarto-figure-center r-stretch" width="432"></section>
<section id="au-total" class="slide level2">
<h2>Au total</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-18-1.png" class="quarto-figure quarto-figure-center r-stretch" width="475"></section>
<section id="observations" class="slide level2">
<h2>Observations</h2>
<p>Deux impératifs apparaissent :</p>
<ul>
<li>Conditionner l’estimation des données manquantes sur les données observées.</li>
<li>Utiliser un modèle de régression adapté.</li>
<li>Garder en tête que l’ensemble reconstruit doit être réutilisé : c’est la grosse différence avec la régression/classification/analyse classique.</li>
</ul>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Une solution ?</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Pourquoi ne pas faire de la régularisation ?</li>
</ul>
<p><span class="math display">\[
\text{Régularisation Ridge : }\ \min_{\alpha, \beta} \ (y-\alpha-x \beta)^2+\lambda \beta^2
\]</span></p>
</div>
</div>
</div>
</section></section>
<section>
<section id="la-régularisation-1" class="title-slide slide level1 center">
<h1>La régularisation (1)</h1>
<ul>
<li><span style="color:gold;">Régression linéaire pénalisée Ridge</span> pour l’imputation.</li>
<li><span style="color:violet;">Régression linéaire</span> pour l’estimation des paramètres.</li>
</ul>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-19-1.png" class="quarto-figure quarto-figure-center r-stretch" width="466"><p><span class="math inline">\(\longrightarrow\)</span> Compromis biais-variance. </p>
</section>
<section id="la-régularisation-2" class="slide level2">
<h2>La régularisation (2)</h2>
<h3 id="conclusion">Conclusion</h3>
<p>La régularisation permet de réduire l’erreur que l’on fait sur l’estimation de <span class="math inline">\(\sigma^2\)</span> au détriment de la variance estimée de <span class="math inline">\(y\)</span></p>
<div class="r-stack">
<p>La prédiction, qui est une espérance conditionelle, ne prend pas en compte l’incertitude liée au modèle (bruit d’observation,…)</p>
</div>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Une solution ?</strong></p>
</div>
<div class="callout-content">
<p>Il faut utiliser une méthode qui introduise cette incertitude</p>
<p>Générer M jeux de données imputés pour obtenir cette variabilité</p>
<div class="r-stack">
<p>C’est <strong>la régression stochastique</strong></p>
</div>
</div>
</div>
</div>
</section>
<section id="la-régression-stochastique---improper-imputation" class="slide level2">
<h2>La régression stochastique - <em>improper imputation</em></h2>
<p>Alors que le modèle de prédiction était précédemment</p>
<p><span class="math display">\[
\hat{y} = \hat{\alpha} + \hat{\beta} x,
\]</span> où <span class="math inline">\(\hat{\beta}\)</span> était estimé sur le jeu de données <span class="math inline">\(S\)</span>, nous allons maintenant utiliser l’estimateur</p>
<p><span class="math display">\[
\tilde{y} = \hat{\alpha} + \hat{\beta} x + \eta,
\]</span> avec <span class="math inline">\(\eta\sim \mathcal{N}(0,\hat{\sigma}^2)\)</span> et <span class="math inline">\(\hat{\sigma}^2\)</span> est estimé sur <span class="math inline">\(S\)</span> via</p>
<p><span class="math display">\[
\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2.
\]</span></p>
</section>
<section id="la-régression-stochastique---improper-imputation-2" class="slide level2">
<h2>La régression stochastique - <em>improper imputation</em> (2)</h2>
<p>On répète un nombre <span class="math inline">\(M=\)</span> 20 d’imputations du jeu de données intitiales. En voici 3 versions.</p>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-20-1.png" class="quarto-figure quarto-figure-center r-stretch" width="518"><p>La moyenne empirique des <span class="math inline">\(M=\)</span> 20 estimations pour chacun des 3 coefficients: <span class="math display">\[
\hat{\alpha}_N\approx -0.031\pm 0.054, \
\hat{\beta}_N\approx 0.984\pm 0.052,\
\hat{\sigma}^2_N\approx 0.22
\]</span></p>
</section>
<section id="le-boxplot-toujours-aussi-utile" class="slide level2">
<h2>Le boxplot, toujours aussi utile</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-21-1.png" class="quarto-figure quarto-figure-center r-stretch" width="864"><p>Les points théoriques sont en dehors des distributions… A-t-on oublié quelque chose ?</p>
</section>
<section id="limputation-multiple---proper-1" class="slide level2">
<h2>L’imputation multiple - <em>proper</em> (1)</h2>
<h3 id="problème">Problème</h3>
<p>Cette solution ne prend pas en compte la variabilité sur les paramètres.</p>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Deux solutions</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong>Bayes</strong> : Tirer <span class="math inline">\(M\)</span> paramètres sur la distribution a posteriori (si définie…). Estimer <span class="math inline">\(M\)</span> jeux de données différents en suivant ces paramètres <span class="citation" data-cites="tannerwong1987">Tanner and Wong (<a href="#/références" role="doc-biblioref" onclick="">1987</a>)</span>, utilisée dans <strong>MICE</strong> <span class="citation" data-cites="mice">van Buuren and Groothuis-Oudshoorn (<a href="#/références" role="doc-biblioref" onclick="">2011</a>)</span></li>
<li><strong>Bootstrapper</strong> <span class="math inline">\((S,\tilde{S})\)</span> pour créer <span class="math inline">\(M\)</span> jeux de données dans lesquels il y a potentiellement des données manquantes, approche de <strong>missMDA</strong> <span class="citation" data-cites="missmda">Josse and Husson (<a href="#/références" role="doc-biblioref" onclick="">2016</a>)</span>.</li>
</ul>
</div>
</div>
</div>
<ul>
<li><p>Ensuite appliquer la méthode d’analyse sur chacun des jeux de données séparément.</p></li>
<li><p>Estimer les paramètres par aggrégation des <span class="math inline">\(M\)</span> modèles.</p></li>
</ul>
<!-- Calculs pour la partie suivante -->
</section>
<section id="limputation-multiple---proper-2" class="slide level2">
<h2>L’imputation multiple - <em>proper</em> (2)</h2>
<p>On obtient des estimations :</p>
<ul>
<li><p>Via bootstrap : <span class="math display">\[
\hat{\alpha}_\text{Boot}\approx -0.017\pm 0.058, \
\hat{\beta}_\text{Boot}\approx 0.992\pm 0.056, \
\hat{\sigma}^2_\text{Boot}\approx 0.249
\]</span></p></li>
<li><p>Via la postérieure/bayésienne : <span class="math display">\[
\hat{\alpha}_\text{Bayes}\approx -0.038\pm 0.064, \
\hat{\beta}_\text{Bayes}\approx 0.982\pm 0.061,\
\hat{\sigma}^2_\text{Bayes}\approx 0.312
\]</span></p></li>
</ul>
<p>Pour rappel, dans les cas impropres : <span class="math display">\[
\begin{array}{lccc}
\text{Moyenne}&amp;\hat{\alpha}_0\approx -0.227\pm 0.077 &amp;
\hat{\beta}_0\approx 0.545\pm 0.073 &amp;
\hat{\sigma}^2_0\approx 0.449\\
\text{Régression linéaire}&amp;\hat{\alpha}_l\approx -0.031\pm 0.05 &amp;
\hat{\beta}_l\approx 0.981\pm 0.048 &amp;
\hat{\sigma}^2_l\approx 0.192\\
\text{Régression stochastique}&amp;\hat{\alpha}_N\approx -0.031\pm 0.054 &amp;
\hat{\beta}_N\approx 0.984\pm 0.052 &amp;
\hat{\sigma}^2_N\approx 0.22
\end{array}
\]</span> </p>
</section>
<section id="règle-de-rubin-rubins-rule" class="slide level2">
<h2>Règle de Rubin (<em>Rubin’s Rule</em>)</h2>
<p>Soit <span class="math inline">\(M\)</span> jeux de données imputés alors la règle de Rubin stipule que <span class="math display">\[
\hat{\theta}_{IM} = \frac{1}{M}\sum_{m=1}^M \hat{\theta}_m,
\]</span> où <span class="math inline">\(\hat{\theta}_m\)</span> est la valeur du paramètre estimé pour le jeu de donné d’indice <span class="math inline">\(m\)</span>. Il vient alors : <span class="math display">\[
\begin{array}{lcl}
\hat{\sigma}^2_{IM} = \hat{\sigma}^2_{W} + (1+\frac{1}{M})\hat{\sigma}^2_{B},\\
\text{variance imputée : }\hat{\sigma}^2_{W} = \frac{1}{M}\sum_{m=1}^M \hat{\sigma}_m^2,\\
\text{variance inter-imputation : }\hat{\sigma}^2_{B} = \frac{1}{M-1}\sum_{m=1}^M (\hat{\theta}_m-\hat{\theta}_{IM})^2.
\end{array}
\]</span> Sachant que les variances par modèle sont estimées via <span class="math display">\[
\begin{array}{lcl}
\hat{\sigma}_m^2(\hat{\alpha})&amp;=&amp;
\hat{\sigma}^2(\frac{1}{n+\tilde{n}}+\frac{\bar{x}^2}{\sum_{i=1}^{n+\tilde{n}}(x_i-\bar{x})^2})\\
\hat{\sigma}_m^2(\hat{\beta})&amp;=&amp;
\hat{\sigma}^2\frac{1}{\sum_{i=1}^{n+\tilde{n}}(x_i-\bar{x})^2}
\end{array}
\]</span> </p>
</section></section>
<section>
<section id="justifications-théoriques" class="title-slide slide level1 center">
<h1>Justifications théoriques</h1>

</section>
<section id="structure-du-cours" class="slide level2">
<h2>Structure du cours</h2>
<p>Dans la suite on considère le cas général d’un modèle paramètrique de paramètre <span class="math inline">\(\theta\in\Theta\)</span></p>
<h3 id="estimation-dun-paramètre-optimal">Estimation d’un paramètre optimal</h3>
<p>Justification de la méthode du maximum de vraisemblance dans le cas de jeux de données avec données manquantes</p>
<h3 id="simulation-de-données-et-de-paramètres">Simulation de données et de paramètres</h3>
<p>Comment simuler, conditionellement aux données observées <span class="math inline">\(X\)</span> :</p>
<ul>
<li>des données manquantes <span class="math inline">\(Z\)</span></li>
<li>des paramètres <span class="math inline">\(\theta\)</span></li>
</ul>
<p>en présence de données manquantes</p>
</section></section>
<section>
<section id="estimation-de-paramètre-algorithme-em" class="title-slide slide level1 center">
<h1>Estimation de paramètre – algorithme EM</h1>

</section>
<section id="maximization-de-vraisemblance" class="slide level2">
<h2>Maximization de vraisemblance</h2>
<p>Soit une fonction de densité paramétrique <span class="math inline">\(p(x|\theta)\)</span> qui dépend du paramètre <span class="math inline">\(\theta\in\Theta\)</span>, <span class="math inline">\(\Theta\)</span> potentiellement multi-dimensionnel.</p>
<p>Dans le cas d’un échantillon de <span class="math inline">\(n\)</span> observations indépendantes <span class="math inline">\(X=(x_1,\dots,x_n)\)</span> la vraisemblance s’écrit : <span class="math display">\[
\mathcal{L}(\theta|X) = \prod_{i=1}^np(x_i|\theta).
\]</span> Plus cette valeur est importante et plus le modèle <span class="math inline">\(\theta\)</span> est vraisemblable suivant les données <span class="math inline">\(X\)</span>. La contrainte de cette fonction est qu’elle doit sommer à 1.</p>
</section>
<section id="maximization-de-vraisemblance-2" class="slide level2">
<h2>Maximization de vraisemblance (2)</h2>
<p>Le meilleur paramètre pour nos données <span class="math inline">\(X\)</span> sera donc celui qui maximise cette vraisemblance.</p>
<p><span class="math display">\[
\max_{\theta\in\Theta}\ \mathcal{L}(\theta|X).
\]</span></p>
<p>Dans le cas d’absence de données manquantes, la solution est l’estimateur <strong>du maximum de vraisemblance</strong>.</p>
<p>Le problème se pose lorsque des données manquent dans <span class="math inline">\(X\)</span>…</p>
</section>
<section id="remarque" class="slide level2">
<h2><span style="color:white;">Remarque</span></h2>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p>L’algorithme EM est une méthode itérative qui permet de maximiser la vraisemblance.</p>
<p>C’est un algorithme d’optimisation, une méthode numérique.</p>
<p>Il est utilisé dans le cadre de la gestion de données manquantes car il permet :</p>
<ul>
<li>d’estimer des données manquantes,</li>
<li>d’estimer les paramètres statistiques du modèle considéré,</li>
<li>d’offir une garantie de maximalité de la vraisemblance.</li>
</ul>
<p>L’algorithme EM <strong>n’est pas</strong> toujours utilisé pour gérer des données manquantes!</p>
</div>
</div>
</div>
</section>
<section id="idée-de-lalgorithme-em" class="slide level2">
<h2>Idée de l’algorithme EM</h2>
<p><strong>EM</strong> (pour <strong>E</strong>xpectation-<strong>M</strong>aximization) permet d’estimer des paramètres <span class="math inline">\(\theta\)</span> dans un modèle à vraisemblance, mais aussi les données manquantes.</p>
<p>C’est un algorithme itératif à deux étapes. On part d’une initialisation et pour une itération <span class="math inline">\(k&gt;0\)</span>, il vient :</p>
<p><br>
</p>
<ul>
<li><strong>E</strong>spérance : approximer les données manquantes en fonction du paramètre courant <span class="math inline">\(\theta_{k}\)</span>. Ceci permet de compléter le jeu de données.</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>M</strong>aximisation : approximer le modèle en fonction du jeu de donnée complété à l’étape précédente.</li>
</ul>
</section>
<section id="naissance-de-lalgorithme-em-1" class="slide level2">
<h2>Naissance de l’algorithme <strong>EM</strong> (1)</h2>
<p>Soit <span class="math inline">\(X\in\mathcal{X}\)</span> les données manquantes et <span class="math inline">\(Z\in\mathcal{Z}\)</span> les données présentes, alors la fonction de densité jointe de <span class="math inline">\((X,Z)\)</span> peut s’écrire <span class="math display">\[
p\left(X,Z|\theta\right)=p\left(X|Z,\theta\right)p\left(Z|\theta\right).
\]</span> Ainsi, par intégration sur <span class="math inline">\(\mathcal{Z}\)</span> l’ensemble formé par les évènements possibles pour les données manquantes il vient <span class="math display">\[
p\left(X|\theta\right) = \int_{z\in \mathcal{Z}}p\left(X,z|\theta\right)dz=\int_{z\in \mathcal{Z}} p\left(X|z,\theta\right)p\left(z|\theta\right)dz
\]</span> L’objectif de l’algorithme est de maximiser la log vraisemblance <span class="math inline">\(\ell(\theta|X)\)</span> : <span class="math display">\[
\ell(\theta|X)=\ln\left(p(X|\theta)\right).
\]</span> <!-- et on note $\widehat{\theta} = \text{arg max}_{\theta\in\Theta}\  l(\theta|x^{(p)}).$--></p>
</section>
<section id="naissance-de-lalgorithme-em-2" class="slide level2">
<h2>Naissance de l’algorithme <strong>EM</strong> (2)</h2>
<p>Si l’on choisit <span class="math inline">\(z\mapsto q(z)\)</span> est une densité de probabilité sur <span class="math inline">\(\mathcal{Z}\)</span> qui est nulle seulement là où <span class="math inline">\(z\mapsto p\left(X,z|\theta\right)\)</span> est aussi nulle, alors :</p>
<p><span class="math display">\[ \begin{align*}
\ell(\theta|X) &amp; = \int_{\mathcal{Z}} q(z) \ell(\theta|X) dz = \int_{\mathcal{Z}} q(z) \ln \left( \frac{p(X|\theta) p(z | X,\theta)}{p(z | X,\theta)} \right) dz, \\
&amp; = \int_{\mathcal{Z}} q(z) \ln \left( \frac{p(X, z| \theta)}{p(z | X,\theta)} \right) dz  = \int_{\mathcal{Z}} q(z) \ln \left( \frac{p(X, z| \theta) q(z)}{p(z | X,\theta) q(z)} \right) dz, \\
&amp; = \int_{\mathcal{Z}} q(z) \ln \left( \frac{p(X, z| \theta)}{q(z)} \right) dz + \int_{\mathcal{Z}} q(z) \ln \left( \frac{q(z)}{p(z | X,\theta)} \right) dz, \\
&amp; = F(q, \theta) + KL\left\{q || p(\cdot|X,\theta)\right\}.
\end{align*}
\]</span></p>
<p>On apelle divergence de Kullblack-Leibler : <span class="math inline">\((p,q)\mapsto D_{KL}\left\{p||q\right\}=\int_{\mathcal{Z}} p\log\left({p}/{q}\right)\)</span> et on peut montrer que cette divergence est positive ou nulle. Nulle si et seulement si <span class="math inline">\(p=q\)</span>.</p>
</section>
<section id="naissance-de-lalgorithme-em-3" class="slide level2">
<h2>Naissance de l’algorithme <strong>EM</strong> (3)</h2>
<p><br>
</p>
<p>Il vient que la fonctionelle <span class="math inline">\((q,\theta)\mapsto F(q,\theta)\)</span> agit comme un minorant de la log-vraisemblance, on l’apelle souvant <strong>Evidence Lower Bound (ELBO)</strong> et ainsi :</p>
<p><span class="math display">\[
\ell(\theta|X)\geq F(q,\theta).
\]</span></p>
<p><br>
</p>
<p>L’objectif de l’<strong>EM</strong> est de maximiser cette fonctionnelle qui va ainsi assurer à la log-vraisemblance d’être maximale.</p>
<p>Pour celà, il faut particulariser la densité <span class="math inline">\(q\)</span>.</p>
</section>
<section id="lalgorithme-em-1" class="slide level2">
<h2>L’algorithme <strong>EM</strong> (1)</h2>
<p>Si l’on connaît la forme de la loi conditionelle de <span class="math inline">\(z\)</span> sachant un paramètre <span class="math inline">\(\theta_0\in\Theta\)</span> et nos données <span class="math inline">\(X\)</span>, on peut écrire <span class="math inline">\(q(z)=p(z|X,\theta_0)\)</span> et il vient :</p>
<p><span class="math display">\[
\begin{array}{c c l}
F(q, \theta) &amp; = &amp; \int_{\mathcal{Z}} q(z) \ln \left( \frac{p(X, z| \theta)}{q(z)} \right) dz,\\
&amp;=&amp; \int_{\mathcal{Z}} p(z|X,\theta_0) \ln \left( \frac{p(X, z| \theta)}{p(z|X,\theta_0)} \right) dz,\\
&amp;=&amp; \int_{\mathcal{Z}} p(z|X,\theta_0) \ln \left( p(X, z| \theta) \right) dz-\int_{\mathcal{Z}} p(z|X,\theta_0) \ln \left( p(z|X,\theta_0) \right) dz,\\
&amp;=&amp;
Q(\theta|\theta_0,X)+cste(\theta_0,q),\\
&amp;=&amp; \mathbb{E}_{\theta_0}\left[\ln{p\left(X,Z|\theta\right)
}\right]+cste(\theta_0,q).
\end{array}
\]</span></p>
<p>Il vient l’objectif, finalement, de maximiser <span class="math inline">\(Q(\theta|\theta_0,X)\)</span>, qui est</p>
<p style="text-align:center;">
<strong>l’espérance conditionelel de la vraisemblance complétée</strong>.
</p>
</section>
<section id="lalgorithme-em-2" class="slide level2">
<h2>L’algorithme <strong>EM</strong> (2)</h2>
<p>L’algorithme EM construit une suite de paramètres <span class="math inline">\(\left(\theta_k\right)_{k\geq0}\)</span> tels que <span class="math inline">\(\forall k&gt;0\)</span> : <span class="math display">\[
\theta_{k+1} = \text{arg max}_{\theta\in\Theta}\ Q(\theta|\theta_{k},X).
\]</span></p>
<p><br>
</p>
<p>Ces éléments vérifient <span class="math inline">\(\ell(\theta_{k+1}|X) \geq \ell(\theta_{k}|X) \geq\ldots\geq \ell(\theta_{0}|X)\)</span>. La suite <span class="math inline">\(\left(\ell(\theta_{k}|X)\right)_{k\geq0}\)</span> est donc croissante. Cette suite est aussi majorée par le maximum de la function maximisée. Cette suite converge donc.</p>
<p><br>
</p>
<p>Dans les faits, cette convergence est lente et se fait souvent vers un maximum local, ce qui nécessite plusieurs initialisations.</p>
</section>
<section id="algorithme-em-et-espérance-conditionelle-2" class="slide level2">
<h2>Algorithme <strong>EM</strong> et espérance conditionelle (2)</h2>
<p><span class="math display">\[
\begin{array}{c c l}
Q\left(\theta|\theta_0,X\right) &amp;=&amp;  \mathbb{E}_{\theta_0}\left[\ln{p\left(X,Z|\theta\right)
}\right].
\end{array}
\]</span> La log-vraisemblance complétée, <span class="math inline">\(\ln{p\left(X,z|\theta\right)}\)</span>, est souvent notée <span class="math inline">\(\ell_c(X,z|\theta)\)</span>. Complétée car les données manquantes, <span class="math inline">\(z\)</span>, sont ajoutées, ce qui permet d’avoir accès à un jeu de données complet <span class="math inline">\(\left(z,X\right)\)</span>.</p>
<p><br>
</p>
<p>Noter, dans un coin de sa tête, que l’espérance conditionelle de la log-vraisemblance complétée est souvent plus simple à calculer que la vraisemblance complète. C’est tout l’intérêt de l’algorithme <strong>EM</strong>. Si ce n’est pas le cas ? Voir bien plus loin…</p>
</section>
<section id="algorithme-em" class="slide level2">
<h2>Algorithme <strong>EM</strong></h2>
<p><br>
</p>
<p>Soit pour l’itération <span class="math inline">\(k\)</span> en ayant initialisé <span class="math inline">\(\theta_{k}\)</span>. On répète les deux étapes suivantes jusqu’à convergence :</p>
<p><br>
</p>
<ul>
<li>Etape <strong>E</strong> : <em>Espérance conditionelle</em> : Evaluation de <span class="math inline">\(Q\left(\theta|\theta_{k},X\right)\)</span>.</li>
</ul>
<p><br>
</p>
<ul>
<li>Etape <strong>M</strong> : <em>Maximisation</em> : de <span class="math inline">\(Q\left(\theta|\theta_{k},X\right)\)</span> pour obtenir <span class="math inline">\(\theta_{k+1}\)</span>.</li>
</ul>
</section>
<section id="remarque-importante" class="slide level2">
<h2>Remarque importante</h2>
<p><br>
</p>
<p>Dans certains cas, le calcul de l’espérance conditionelle revient au calcul des espérances conditionelles des variables latentes <span class="math inline">\(z_i\)</span>.</p>
<p><br>
</p>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p>On voit souvent la notation <span class="math display">\[\mathbb{E}_{\theta_{k}}[Z_i] = &lt;\!\!z_i\!\!&gt;_k.\]</span></p>
</div>
</div>
</div>
</section>
<section id="un-petit-exemple-1" class="slide level2">
<h2>Un petit exemple (1)</h2>
<p>On accède aux données d’un capteur de température qui sature à partir d’une température <span class="math inline">\(a\)</span>. On sait que la température suit une loi normale de moyenne <span class="math inline">\(\theta\)</span> et de variance <span class="math inline">\(1\)</span>. Parmi les <span class="math inline">\(n=n_1+n_2\)</span> données, les <span class="math inline">\(n_1\)</span> premières ne sont pas saturées (<span class="math inline">\(x_i&lt;a\)</span>) alors que les <span class="math inline">\(n_2\)</span> suivantes sont saturées (<span class="math inline">\(x_i\geq a\)</span>). On cherche tout de même à estimer <span class="math inline">\(\theta\)</span>, la vraie valeur de la température.</p>
<p>Dans ce cas, la vraisemblance du problème s’écrit <span class="math display">\[
\mathcal{L}(\theta|X) = \left(1-\Phi(a-\theta)\right)^{n_2}\prod_{i=1}^{n_1}\varphi(x_i-\theta),
\]</span> où <span class="math inline">\(\varphi\)</span> et <span class="math inline">\(\Phi\)</span> sont les fonctions de densité et de répartition de la loi normale centrée réduite.</p>
</section>
<section id="un-petit-exemple-2" class="slide level2">
<h2>Un petit exemple (2)</h2>
<p>On introduit des variables latentes <span class="math inline">\(z_i\)</span> et on écrit alors la vraisemblance complétée <span class="math display">\[
\mathcal{L}_c(\theta|X,Z) = \prod_{i=1}^{n_1}\varphi(x_i-\theta)\prod_{i=1}^{n_2}\varphi(z_i-\theta),
\]</span> qui est cette fois simple à régler puisque les <span class="math inline">\(z_i\)</span> sont observés.</p>
<p><br>
</p>
<p>C’est l’étape de maximization qui permet de trouver le paramètre <span class="math inline">\(\theta\)</span> optimal.</p>
</section>
<section id="un-petit-exemple-3" class="slide level2">
<h2>Un petit exemple (3)</h2>
<p><br>
</p>
<p>On peut aisemment détailler la vraisemblance complétée <span class="math inline">\(\ell_c(\theta|X,Z)\)</span> :</p>
<p><span class="math display">\[
\ell_c(\theta|X,Z) = -\frac{1}{2}\sum_{i=1}^{n_1} (x_i-\theta)^2 -\frac{1}{2} \sum_{i=1}^{n_2}(z_i-\theta)^2 + cste.
\]</span></p>
<p><br>
</p>
<p>L’<strong>espérance conditionelle de la log-vraisemblance complétée</strong> est alors</p>
<p><span class="math display">\[
Q(\theta|\theta_k,X) = \mathbb{E}_{\theta_k}\left[\ell_c(\theta|X,Z)\right] = -\frac{1}{2}\sum_{i=1}^{n_1} (x_i-\theta)^2 -\frac{1}{2} \sum_{i=1}^{n_2}\mathbb{E}_{\theta_k}[(Z_i-\theta)^2] + cste.
\]</span></p>
</section>
<section id="un-petit-exemple-4" class="slide level2">
<h2>Un petit exemple (4)</h2>
<p><br>
</p>
<p>La fonctionelle <span class="math inline">\(Q(\theta|\theta_k,X)\)</span> est alors maximale en <span class="math display">\[
\theta_{k+1} = \frac{\sum_{i=1}^{n_1}x_i+\sum_{i=1}^{n_2}&lt;\!\!z_i\!\!&gt;_k}{n}
\]</span></p>
<p><br>
</p>
<p>et le terme en <span class="math inline">\(n_2\)</span> a tendance à tirer la moyenne vers lui. Pour ce qui est de <span class="math inline">\(&lt;\!\!z_i\!\!&gt;_k\)</span> : <span class="math display">\[
&lt;\!\!z_i\!\!&gt;_k=\mathbb{E}_{\theta_k}[Z_i]=\dfrac{\int_{a}^{\infty}z\varphi(z-\theta_k)dz}{1-\Phi(a-\theta_k)} = \theta_k + \dfrac{\varphi(a-\theta_k)}{1-\Phi(a-\theta_k)}.
\]</span></p>
</section>
<section id="un-petit-exemple-5" class="slide level2">
<h2>Un petit exemple (5)</h2>
<p><br>
</p>
<p>L’algorithme <strong>EM</strong> recherché réalise donc les deux étapes suivantes, après initialisation de <span class="math inline">\(\theta\)</span> via <span class="math inline">\(\theta_0\)</span>, et pour toute itération <span class="math inline">\(k&gt;0\)</span> :</p>
<ul>
<li><strong>Espérance</strong> : Calcul de <span class="math inline">\(Q(\theta|\theta_k,X)\)</span>, celà revient ici à calculer:</li>
</ul>
<p><span class="math display">\[\forall i\in\{1,\dots,n_2\},\quad &lt;\!\!z_i\!\!&gt;_k = \theta_k + \dfrac{\varphi(a-\theta_k)}{1-\Phi(a-\theta_k)}=&lt;\!\!z_1\!\!&gt;_k.\]</span></p>
<p><br>
</p>
<ul>
<li><strong>Maximisation</strong> : on calcule <span class="math inline">\(\theta_{k+1} = \dfrac{\sum_{i=1}^{n_1}x_i+n_2&lt;\!\!z_1\!\!&gt;_k}{n}\)</span>.</li>
</ul>
</section>
<section id="un-petit-exemple-6" class="slide level2">
<h2>Un petit exemple (6)</h2>
<p>Application numérique avec <span class="math inline">\(\theta=30\)</span>, <span class="math inline">\(n_1=400\)</span>, <span class="math inline">\(n_2=250\)</span> et <span class="math inline">\(a=30.27\)</span> :</p>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-24-1.png" class="quarto-figure quarto-figure-center r-stretch" width="544"></section>
<section id="algorithme-em-retour-à-notre-exemple" class="slide level2">
<h2>Algorithme <strong>EM</strong>, retour à notre exemple</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/emResult-1.png" class="quarto-figure quarto-figure-center r-stretch" width="388"><p>Les valeurs estimées sont alors <span class="math display">\[
\hat{\alpha}_\text{EM}\approx -0.036\pm 0.043, \
\hat{\beta}_\text{EM}\approx 0.969\pm 0.043,\
\hat{\sigma}^2_\text{EM}\approx 0.15
\]</span></p>
</section></section>
<section>
<section id="monte-carlo-em" class="title-slide slide level1 center">
<h1>Monte-Carlo EM</h1>

</section>
<section id="raison-dêtre" class="slide level2">
<h2>Raison d’être</h2>
<p>On utilise l’algorithm EM car la fonctionelle <span class="math inline">\(Q(\cdot|\theta_0,X)\)</span> est, nous l’espérons, simple à écrire.</p>
<div class="r-stack">
<p><strong>Que faire si ce n’est pas le cas ?</strong></p>
</div>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Monte-Carlo EM (MCEM, <span class="citation" data-cites="weiTanner90">Wei and Tanner (<a href="#/références" role="doc-biblioref" onclick="">1990</a>)</span>)</strong></p>
</div>
<div class="callout-content">
<p>On remplace <span class="math inline">\(Q(\cdot|\theta_k,X)\)</span> par une approximation Monte-Carlo. L’étape <strong>E</strong> devient :</p>
<p><span class="math display">\[\begin{align}
Z_{k,t}&amp;\sim p(Z|X,\theta_k),\\
\widehat{Q}_T(\theta|\theta_k,X) &amp;= \frac{1}{T}\sum_{t=1}^T \ell_c(X,Z_{k,t}|\theta),
\end{align}\]</span> et alors <span class="math inline">\(\widehat{Q}_T(\cdot|\theta_k,X)\ \underset{T\to\infty}{\longrightarrow}\ Q(\cdot|\theta_k,X)\)</span> par application de la loi des grands nombres.</p>
</div>
</div>
</div>
</section>
<section id="esprit-de-mcem" class="slide level2">
<h2>Esprit de MCEM</h2>
<p><br>
</p>
<ul>
<li><strong>Initialisation</strong> : On initialise <span class="math inline">\(\theta_0\)</span> et on fixe <span class="math inline">\(T\)</span> le nombre de simulations</li>
</ul>
<p><br>
</p>
<ul>
<li>Etape <strong>E</strong> : Calcul de <span class="math inline">\(\widehat{Q}_T(\cdot|\theta_k,X)\)</span></li>
</ul>
<p><br>
</p>
<ul>
<li>Etape <strong>M</strong> : On met à jour le paramètre <span class="math inline">\(\theta\)</span> qui maximise <span class="math inline">\(\widehat{Q}_T(\cdot|\theta_k,X)\)</span></li>
</ul>
<p><br>
</p>
<ul>
<li>On répète les deux étapes précédentes jusqu’à convergence</li>
</ul>
</section>
<section id="remarque-1" class="slide level2">
<h2><span style="color:white;">Remarque</span></h2>
<p><br>
</p>
<p><br>
</p>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p>La suite ainsi construite des vraisemblances n’est pas assurée d’être monotone</p>
</div>
</div>
</div>
</section>
<section id="exemple-des-cellules-1-voir-dempster77" class="slide level2">
<h2>Exemple des cellules (1), voir <span class="citation" data-cites="dempster77">Dempster, Laird, and Rubin (<a href="#/références" role="doc-biblioref" onclick="">1977</a>)</span></h2>
<p>Soit un échantillon biologique peuplé de 4 types cellulaires différents, <span class="math inline">\(X=(x_1,x_2,x_3,x_4)\)</span>, le nombre de chaque type cellulaire dans l’échantillon biologique. On considère le modèle multinomiale suivant :</p>
<p><span class="math display">\[
(x_1,x_2,x_3,x_4) ~\sim ~\mathcal{M}\left(n;\dfrac{2+\theta}{4},\dfrac{1-\theta}{4},\dfrac{1-\theta}{4},\dfrac{\theta}{4},\right),
\]</span> et le paramètre inconnu est <span class="math inline">\(\theta\in[0,1]\)</span>. La vraisemblance de l’échantillon, de taille 1, s’écrit <span class="math display">\[
\mathcal{L}(\theta|X) = (2+\theta)^{x_1}(1-\theta)^{x_2+x_3}\theta^{x_4},
\]</span> qui n’est pas forcemment simple à maximiser.</p>
</section>
<section id="exemple-des-cellules-2" class="slide level2">
<h2>Exemple des cellules (2)</h2>
<p>On introduit deux variables latentes <span class="math inline">\(z_1\)</span> et <span class="math inline">\(z_2\)</span> telles que <span class="math inline">\(x_1=z_1+z_2\)</span>. <span class="math inline">\(z_2\)</span> suit une loi binomiale de paramètre <span class="math inline">\(\left(x_1,\dfrac{\theta}{\theta+2}\right)\)</span>. La log-vraisemblance complétée s’écrit alors</p>
<p><span class="math display">\[
\ell_c(\theta|X,z_2) = (x_2+x_3)\log(1-\theta) + (z_2+x_4)\log(\theta),
\]</span></p>
<p>et là on sait gérer <strong>:)</strong> car l’espérance conditionelle sur <span class="math inline">\(\theta_k\)</span> s’écrit : <span class="math display">\[
Q(\theta|\theta_k,X) = (x_2+x_3)\log(1-\theta) + (&lt;\!\!z_2\!\!&gt;_k+x_4)\log(\theta),
\]</span> avec <span class="math inline">\(&lt;\!\!z_2\!\!&gt;_k= \dfrac{\theta_k}{2+\theta_k}x_1\)</span>, ça c’est l’EM classique avec : <span class="math display">\[
\widehat{\theta}_{k+1} = \dfrac{&lt;\!\!z_2\!\!&gt;_k+x_4}{&lt;\!\!z_2\!\!&gt;_k+x_4 + x_2+x_3}
\]</span></p>
</section>
<section id="exemple-des-cellules-3" class="slide level2">
<h2>Exemple des cellules (3)</h2>
<p>En MCEM, on simule <span class="math inline">\(T\)</span> valeurs pour <span class="math inline">\(z_2~\sim\mathcal{B}\text{inom}(x_1,\dfrac{\theta_k}{2+\theta_k})\)</span>, notées <span class="math inline">\(\left(z_{2,k,t}\right)_t\)</span> et on construit la statistique d’intérêt :</p>
<p><span class="math display">\[
\widehat{Q}_T(\theta|\theta_k,X) = \dfrac{1}{T}\sum_{t=1}^T \ell_c(\theta|X,z_{2,k,t}) = (x_2+x_3)\log(1-\theta)+ \left(\dfrac{1}{T}\sum_{t=1}^Tz_{2,t}+x_4\right)\log(\theta).
\]</span> Ainsi, en notant <span class="math inline">\(\widehat{&lt;\!\!z_2\!\!&gt;_k} = \dfrac{1}{T}\sum_{t=1}^Tz_{2,k,t}\)</span>, la valeur mise à jour de <span class="math inline">\(\theta\)</span> devient <span class="math display">\[
\check{\theta}_{k+1} = \dfrac{\widehat{&lt;\!\!z_2\!\!&gt;_k}+x_4}{\widehat{&lt;\!\!z_2\!\!&gt;_k}+x_4 + x_2+x_3}
\]</span></p>
</section>
<section id="exemple-des-cellules-4" class="slide level2">
<h2>Exemple des cellules (4)</h2>
<p><span class="math display">\[
(x_1,x_2,x_3,x_4) = (115,35,40,10)\quad \text{et} \quad \theta=0.3
\]</span></p>
<p><br>
</p>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/unnamed-chunk-26-1.png" class="quarto-figure quarto-figure-center r-stretch" width="777"></section>
<section id="remarque-ridge" class="slide level2">
<h2><span style="color:white;">Remarque Ridge</span></h2>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Remarque sur l’exemple</strong></p>
</div>
<div class="callout-content">
<p>Dans cet exemple, il est inutile d’avoir recours au MCEM, mais ce n’est pas toujours le cas</p>
</div>
</div>
</div>
<p><br>
</p>
<p><br>
</p>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Remarque générale</strong></p>
</div>
<div class="callout-content">
<p>Si <span class="math inline">\(T=1\)</span> on parle de <strong>stochastic EM</strong> (SEM)</p>
</div>
</div>
</div>
</section>
<section id="modèle-logit-à-effet-aléatoire-1" class="slide level2">
<h2>Modèle logit à effet aléatoire (1)</h2>
<p>On considère le modèle logit à effet aléatoire suivant <span class="citation" data-cites="boothHobert1999">(voir <a href="#/références" role="doc-biblioref" onclick="">Booth and Hobert 1999</a>)</span> :</p>
<p><span class="math display">\[\begin{align}
[Y_{i,j}|x_{i,j},z_i,\beta] &amp; \sim\mathcal{B}\text{ernoulli}\left(\dfrac{\exp(\beta x_{i,j}+z_i)}{1+\exp(\beta x_{i,j}+z_i)}\right),\\
Z_i&amp;\sim\mathcal{N}(0,\sigma^2),
\end{align}\]</span> où <span class="math inline">\(Z_i\)</span> est l’effet aléatoire de l’individu <span class="math inline">\(i\)</span> et la modalité <span class="math inline">\(j\)</span> allant de 1 à <span class="math inline">\(m\)</span>. On écrit la vraisemblance complétée de ce modèle <span class="math display">\[
\mathcal{L}_c(\beta,\sigma^2|X,Y,Z) = \dfrac{1}{\sqrt{\sigma^2}^n}
\text{e}^{-\sum_i\frac{z_i^2}{2\sigma^2}}
\prod_{i,j}\dfrac{\exp(y_{i,j}(\beta x_{i,j}+z_i))}{1+\exp(\beta x_{i,j}+z_i)}.
\]</span> et son pendant logarithmique est alors : <span class="math display">\[
\begin{array}{c c c}
\ell_c(\beta,\sigma^2|X,Y,Z) &amp;=&amp; -n\log \sigma - \dfrac{\sum_{i}z_i^2}{2\sigma^2}+\sum_{i,j}y_{i,j}(\beta x_{i,j}+z_i)\\
&amp;&amp;- \sum_{i,j}\log(1+\exp(\beta x_{i,j}+z_i)).
\end{array}
\]</span></p>
</section>
<section id="modèle-logit-à-effet-aléatoire-2" class="slide level2">
<h2>Modèle logit à effet aléatoire (2)</h2>
<p><br>
</p>
<p>L’espérance conditionelle de son logarithme, pour un paramètre <span class="math inline">\(\theta_0=(\beta_0,\sigma_0^2)\)</span> :</p>
<p><span class="math display">\[
\begin{array}{c c c}
Q(\theta|\theta_0,X,Y) &amp;=&amp; -n\log \sigma - \dfrac{\sum_{i}\mathbb{E}_{\theta_0}[Z_i^2]}{2\sigma^2}+\sum_{i,j}y_{i,j}(\beta x_{i,j}+\mathbb{E}_{\theta_0}[Z_i])\\
&amp;&amp;- \sum_{i,j}\mathbb{E}_{\theta_0}[\log(1+\exp(\beta x_{i,j}+Z_i))].
\end{array}
\]</span></p>
<p><br>
</p>
<p>La maximisation en <span class="math inline">\(\sigma\)</span> est possible : <span class="math display">\[
\tilde{\sigma}^2 = \dfrac{1}{n}\sum_{i}\mathbb{E}_{\theta_0}[Z_i^2],
\]</span> mais la maximisation en <span class="math inline">\(\beta\)</span> est plus complexe…</p>
</section>
<section id="modèle-logit-à-effet-aléatoire-3" class="slide level2">
<h2>Modèle logit à effet aléatoire (3)</h2>
<p>D’après la forme de la vraisemblance complétée, on peut déduire la forme de la loi conditionelle des <span class="math inline">\(Z_i\)</span> : <span class="math display">\[
[Z_i|(x_{i,j},y_{i,j})_j,\beta,\sigma^2] \propto
\frac{\text{e}^{-\dfrac{\left(Z_i-\sigma^2\sum_{j} y_{i,j}\right)^2}{2\sigma^2}}}{\prod_{j} \left(1+\exp\left(\beta x_{i,j}+Z_i\right)\right)}.
\]</span></p>
<p>En <em>oubliant</em> le dénominateur on pourrait croire que <span class="math display">\[
[Z_i|(x_{i,j},y_{i,j})_j,\beta,\sigma^2]\sim\mathcal{N}(\sigma^2\sum_{j} y_{i,j},\sigma^2),
\]</span> mais ce n’est pas le cas…</p>
<p>Il est nécessaire d’avoir recours à des méthodes d’échantillonnage de type MCMC.</p>
</section>
<section id="modèle-logit-à-effet-aléatoire-4" class="slide level2">
<h2>Modèle logit à effet aléatoire (4)</h2>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Simulation des <span class="math inline">\(Z_i\)</span> : algorithme d’acceptation rejet</strong></p>
</div>
<div class="callout-content">
<p>On va utiliser un algorithm d’acceptation-rejet pour simuler chacun des <span class="math inline">\(Z_i\)</span>, indépendemment. A l’instant <span class="math inline">\(t\)</span>, on utilise la loi instrumentale <span class="math inline">\(\mathcal{N}(z_{i,t-1},\sigma^2)\)</span> pour simuler un candidat <span class="math inline">\(\check{z}_{i}\)</span>. On calcule le taux d’acceptation <span class="math display">\[
\alpha_i=
  \dfrac
{p(\check{z}_{i}|(x_{i,j},y_{i,j})_j,\beta,\sigma^2)}
{p(z_{i,t-1}|(x_{i,j},y_{i,j})_j,\beta,\sigma^2)}.
\]</span> On tire alors un <span class="math inline">\(U\)</span> uniformemment sur <span class="math inline">\([0,1]\)</span> : <span class="math inline">\(z_{i,t}\gets \check{z}_{i}\)</span> si <span class="math inline">\(U\leq\alpha_i\)</span> et <span class="math inline">\(z_{i,t}\gets z_{i,t-1}\)</span> sinon.</p>
</div>
</div>
</div>
<p>Il vient alors l’étape <strong>M</strong> de MCEM : <span class="math display">\[
\begin{array}{ccl}
\hat{\sigma}^2 &amp;=&amp; \dfrac{1}{nT}\sum_{i,t}z_{i,t}^2,\\
\hat{\beta} &amp;=&amp; \text{arg}\underset{\beta}{\max} \underset{i,j,t}{\sum}y_{i,j}(\beta x_{i,j}+z_{i,t})-\log(1+\exp(\beta x_{i,j}+z_{i,t})).
\end{array}
\]</span></p>
</section>
<section id="modèle-logit-à-effet-aléatoire-5" class="slide level2">
<h2>Modèle logit à effet aléatoire (5)</h2>
<div class="r-stack">
<p>Il ne reste plus qu’à implémenter, exercice laissé au lecteur</p>
</div>
<p><br>
</p>
<div class="r-stack">
<p><img src="files/mcem_dur.pdf" alt="some text" width="700"></p>
</div>
</section>
<section id="conclusion-sur-mcem" class="slide level2">
<h2>Conclusion sur MCEM</h2>
<p><br>
</p>
<ul>
<li><strong>Avantages</strong> : permet de contourner des problèmes de calculs de vraisemblances conditionelles complexes</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>Inconvénients</strong> :
<ul>
<li>nécessité de simuler des données, ce qui peut être coûteux en temps de calcul</li>
<li>nécessité d’un critère de convergence adapté</li>
<li>pas de prise en compte de la variabilité associée au mécnaisme de données manquantes</li>
</ul></li>
</ul>
</section>
<section id="vbem-plus-loin-avec-lem-1" class="slide level2">
<h2>VBEM : plus loin avec l’EM (1)</h2>
<p>La méthode <strong>Variational Bayes EM</strong> (VBEM) est une extension de l’EM qui permet de contourner les problèmes de calculs de vraisemblances conditionelles complexes en supposant que la distribution postérieure des données est formée par le produit d’une densité en <span class="math inline">\(Z\)</span>, les données manquantes, et d’une densité en <span class="math inline">\(\theta\)</span>, le paramètre :</p>
<p><span class="math display">\[
p(Z,\theta|X) \approx q_Z(Z|X)q_\theta(\theta|X)=q(Z,\theta|X).
\]</span></p>
<p>on associe <span class="citation" data-cites="attias1999variational">Attias (<a href="#/références" role="doc-biblioref" onclick="">1999</a>)</span> à la découverte de cette méthode, mais d’autres travaux (beaucoup) existent. Voir les travaux de Hinton, récemment primés par un prix Nobel de physique.</p>
</section>
<section id="vbem-plus-loin-avec-lem-2" class="slide level2">
<h2>VBEM : plus loin avec l’EM (2)</h2>
<p>L’idée est d’estimer les lois en <span class="math inline">\(Z\)</span> et en <span class="math inline">\(\theta\)</span> alternativement.</p>
<p>Ecrire les équations nécessite d’introduire un nouvel objet : <strong>la vraisemblance marginale</strong>. Cette distribution marginalise sur les paramètres <span class="math inline">\(\theta\)</span> en supposant un modèle paramétrique <span class="math inline">\(m\)</span>, en substance :</p>
<p><span class="math display">\[
\begin{array}{c c l}
\log p(X|m) &amp;=&amp; \log \int_{\Theta\times \mathcal{Z}} p(X,Z,\theta|m)d\theta dZ,\\
&amp;=&amp; \log \int_{\Theta\times \mathcal{Z}} q(Z,\theta|X) \dfrac{p(X,Z,\theta|m)}{q(Z,\theta|X) }d\theta dZ,\\
&amp;\geq&amp;  \int_{\Theta\times \mathcal{Z}} q(Z,\theta|X) \log\left(\dfrac{p(X,Z,\theta|m)}{q(Z,\theta|X) }\right)d\theta dZ,\\
&amp;\geq&amp; \int_{\Theta\times \mathcal{Z}} q_Z(Z|X)q_\theta(\theta|X) \log\left(\dfrac{p(X,Z,\theta|m)}{q_Z(Z|X)q_\theta(\theta|X) }\right)d\theta dZ\  =:\ F_{m}(q_Z,q_\theta,X),\\
\end{array}
\]</span> d’après l’inégalité de Jensen appliquée à la fonction <span class="math inline">\(\log\)</span> car <span class="math inline">\(q(Z,\theta|X)\)</span> somme à 1. <span class="math inline">\(F_{m}(q_Z,q_\theta,X)\)</span> est donc un minorant de la log-<strong>vraisemblance marginale</strong>.</p>
</section>
<section id="vbem-plus-loin-avec-lem-3" class="slide level2">
<h2>VBEM : plus loin avec l’EM (3)</h2>
<p>La fonctionelle <span class="math inline">\(F_{m}(q_Z,q_\theta,X)\)</span> est maximisée par rapport à <span class="math inline">\(q_Z\)</span> et <span class="math inline">\(q_\theta\)</span> <span class="citation" data-cites="neal1998view">(voir <a href="#/références" role="doc-biblioref" onclick="">Neal and Hinton 1998</a>)</span> pour donner l’algorithme <strong>VBEM</strong> :</p>
<ul>
<li>Etape <strong>E</strong> : Choisir <span class="math inline">\(q_Z^{(t)}\)</span> qui maximise <span class="math inline">\(q_Z\mapsto F_{m}(q_Z,q_\theta^{(t-1)},X)\)</span>,</li>
<li>Etape <strong>M</strong> : Choisir <span class="math inline">\(q_\theta^{(t)}\)</span> qui maximise <span class="math inline">\(q_\theta\mapsto F_{m}(q_Z^{(t)},q_\theta,X)\)</span>.</li>
</ul>
<p>Pour aller plus loin, il faudra lire les dits papiers</p>
<!-- ------------------------------------ -->
<!-- ------------------------------------ -->
<!-- ------------------------------------ -->
</section></section>
<section>
<section id="méthodes-déchantillonnage" class="title-slide slide level1 center">
<h1>Méthodes d’échantillonnage</h1>

</section>
<section id="introduction-1" class="slide level2">
<h2>Introduction</h2>
<p>Nous avons discuteé de la méthode EM qui fournit un estimateur du maximum de vraissemblance, ensuite nous avons survolé la méthode VBEM qui permet d’estimer la distribution postérieure approchée à la fois des paramètres et des données manquantes.</p>
<p>Dans cette section nous allons discuter des méthodes d’échantillonnage qui permettent d’estimer la distribution postérieure des paramètres et des données manquantes conditionellement aux données observées.</p>
</section></section>
<section>
<section id="comparaison-des-approches" class="title-slide slide level1 center">
<h1>Comparaison des approches</h1>

</section>
<section id="au-total-1" class="slide level2">
<h2>Au total</h2>
<p><span class="math display">\[
\hat{\alpha}_\text{EM}\approx -0.036\pm 0.043, \
\hat{\beta}_\text{EM}\approx 0.969\pm 0.043,\
\hat{\sigma}^2_\text{EM}\approx 0.15
\]</span> <span class="math display">\[
\hat{\alpha}_\text{Boot}\approx -0.017\pm 0.058, \
\hat{\beta}_\text{Boot}\approx 0.992\pm 0.056, \
\hat{\sigma}^2_\text{Boot}\approx 0.249
\]</span> <span class="math display">\[
\hat{\alpha}_\text{Bayes}\approx -0.038\pm 0.064, \
\hat{\beta}_\text{Bayes}\approx 0.982\pm 0.061,\
\hat{\sigma}^2_\text{Bayes}\approx 0.312
\]</span> <span class="math display">\[
\hat{\alpha}_\text{0}\approx -0.227\pm 0.077, \
\hat{\beta}_\text{0}\approx 0.545\pm 0.073, \
\hat{\sigma}^2_\text{0}\approx 0.449
\]</span> <span class="math display">\[
\hat{\alpha}_l\approx -0.031\pm 0.05, \
\hat{\beta}_l\approx 0.981\pm 0.048, \
\hat{\sigma}^2_l\approx 0.192
\]</span> <span class="math display">\[
\hat{\alpha}_\text{N}\approx -0.031\pm 0.054, \
\hat{\beta}_\text{N}\approx 0.984\pm 0.052, \
\hat{\sigma}^2_\text{N}\approx 0.22
\]</span></p>
</section>
<section id="une-petite-acp-les-individus" class="slide level2">
<h2>Une petite ACP ? Les individus</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/acp-1.png" class="quarto-figure quarto-figure-center r-stretch" width="544"></section>
<section id="une-petite-acp-les-variables" class="slide level2">
<h2>Une petite ACP ? Les variables</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/acp2-1.png" class="quarto-figure quarto-figure-center r-stretch" width="388"></section>
<section id="en-relançant-plusieurs-fois-1" class="slide level2">
<h2>… en relançant plusieurs fois… (1)</h2>
<p>On trace les ellipses de confiance à 95%</p>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/acpMulti-1.png" class="quarto-figure quarto-figure-center r-stretch" width="622"></section>
<section id="en-relançant-plusieurs-fois-2" class="slide level2">
<h2>… en relançant plusieurs fois… (2)</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/acpMulti2-1.png" class="quarto-figure quarto-figure-center r-stretch" width="622"></section>
<section id="dans-lespace-de-base-1" class="slide level2">
<h2>Dans l’espace de base (1)</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/base1-1.png" class="quarto-figure quarto-figure-center r-stretch" width="622"></section>
<section id="dans-lespace-de-base-2" class="slide level2">
<h2>Dans l’espace de base (2)</h2>

<img data-src="M2_stats_de_la_SD_2024_files/figure-revealjs/base2-1.png" class="quarto-figure quarto-figure-center r-stretch" width="622"></section>
<section id="conclusion-1" class="slide level2">
<h2>Conclusion</h2>
<ul>
<li>Construire un modèle statistique et le raffiner tant que possible</li>
</ul>
<p><br>
</p>
<ul>
<li>Ne pas utiliser l’imputation à la moyenne, ni même la régression linéaire non stochastique, pour réaliser de l’inférence sur des paramètres</li>
</ul>
</section></section>
<section>
<section id="en-pratique" class="title-slide slide level1 center">
<h1>En pratique</h1>

</section>
<section id="un-passage-à-léchelle-nécessaire" class="slide level2">
<h2>Un passage à l’échelle nécessaire</h2>
<p>Nous avons vu les principales caractéristiques de l’imputation par comparaison à la régression classique.</p>
<p>En pratique, les jeux de données ne sont pas bivariés et les NA ne sont pas que dans une seule variable…</p>
<p>Dommage…</p>
<p>Des modifications de ce que nous venons de voir ont été imaginées afin de gérer la présence de NA dans le cas général.</p>
</section>
<section id="missmda" class="slide level2">
<h2><strong>missMDA</strong></h2>
<ul>
<li>Utilisation de méthodes factorielles.</li>
<li>Variables qualitatives/quantitatives/mixtes.</li>
<li>Imputation simple/multiple.</li>
<li>Echantillonnage bootstrap/bayésienne.</li>
<li>Beaucoup de choses à dire…</li>
</ul>
</section>
<section id="amelia-ii-algorithme-emb-honkin10" class="slide level2">
<h2><strong>Amelia II</strong> (algorithme <strong>EMB</strong>), <span class="citation" data-cites="HonKin10">Honaker and King (<a href="#/références" role="doc-biblioref" onclick="">2010</a>)</span></h2>
<ul>
<li>Hypothèse d’un jeu de donnée complété qui suit une distribution normale multivariée (<span class="math inline">\(p\)</span> variables) de paramètre <span class="math inline">\((\mu,\Sigma)\)</span>.</li>
<li>Bootstrap ou bayésienne</li>
</ul>
<p>Echantillonnage bootstrap et imputation via algorithme EM… EMB(ootstrap).</p>
</section>
<section id="mice" class="slide level2">
<h2><strong>mice</strong></h2>
<p>Modèles conditionnels chaînés.</p>
<p>Utilise une pénalisation Ridge dans l’imputation, paramètre <span class="math inline">\(\kappa\)</span> de l’ordre de <span class="math inline">\(\kappa=0.0001\)</span> (<span class="math inline">\(\kappa=0.1\)</span> est grand dans ce cas et <em>“may introduce a systematic bias toward the null, and should thus be avoided”</em>)</p>
<p>4 modèles d’imputation :</p>
<ul>
<li><code>norm.predict</code> : imputation sans alea,</li>
<li><code>norm.nob</code> : imputation stochastique,</li>
<li><code>norm</code> : imputation stochastique et postérieure/bayésienne,</li>
<li><code>norm.boot</code> : Estimtation des paramètres sut un échantillon bootstrap des données observées.</li>
</ul>
</section>
<section id="mice-2" class="slide level2">
<h2><strong>mice</strong> (2)</h2>
<p>Les variables sont organisées par nombre d’obs. NA croissant. Un modèle sur la première variable conditionellement aux autres est construit. Les données manquantes sont imputées grâce à ce modèle. C’est au tour de la variable suivante etc… On recommence jusqu’à convergence.</p>
<p>Voir <a href="https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:norm">Vignette</a><sup>1</sup>.</p>
<aside><ol class="aside-footnotes"><li id="fn3"><p><a href="https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:norm" class="uri">https://stefvanbuuren.name/fimd/sec-linearnormal.html#def:norm</a></p></li></ol></aside></section>
<section id="missforest" class="slide level2">
<h2><strong>missForest</strong></h2>
<ul>
<li>Utilisation de “random forests”</li>
<li>Variables qualitatives/quantitatives/mixtes.</li>
<li>Imputation simple.</li>
</ul>
<p>Les variables sont organisées par nombre d’obs. NA croissant. Un modèle sur la première variable conditionellement aux autres est construit, sur les observations présentes pour cette variable. Les données manquantes sont imputées grâce à ce modèle. C’est au tour de la variable suivante etc… On recommence jusqu’à convergence.</p>
</section>
<section id="k-nn-troyanskaya2001" class="slide level2">
<h2><strong>k-NN</strong>, <span class="citation" data-cites="troyanskaya2001">Troyanskaya et al. (<a href="#/références" role="doc-biblioref" onclick="">2001</a>)</span></h2>
<ul>
<li>Non-itérative.</li>
<li>Imputation simple. Pour une observation avec des NA, utilise les observations La fonction <code>impute.knn</code> du package <code>impute</code>. Le paramètre le plus important est <code>k</code>, le nombre de plus proches voisins.</li>
<li>Package <code>impute</code> : <strong>kNN</strong> réalisé sur les variables et non les observations. Données quantitatives. Distance euclidienne.</li>
<li>Package <code>VIM</code>. Données mixtes. Distance de Gower.</li>
</ul>
</section>
<section id="imputation-en-grande-dimension" class="slide level2">
<h2>Imputation en grande dimension</h2>
<p>L’imputation en grande dimension a tendance à ne faire ressortir que les premières dimensions du jeu de donnée (nombre de composantes en ACP).</p>
<p>Or en grande dimension, les dimensions associées avec la réponse ne sont pas forcemment dans les premières dimensions du jeu de données.</p>
<p><strong>Exemple</strong> : Ebola et données génétiques, dataset rVSV_ZEBOV <span class="citation" data-cites="rechtien2017systems">Rechtien et al. (<a href="#/références" role="doc-biblioref" onclick="">2017</a>)</span>.</p>
<p>Il convient d’imputer en prenant en compte l’information que l’on souhaite retrouver (<strong>y</strong>). C’était l’objet de ma thèse et de la méthode <strong>Koh-Lanta</strong>, voir <span class="citation" data-cites="lorenzo2019supervised">LORENZO, SARACCO, and THIÉBAUT (<a href="#/références" role="doc-biblioref" onclick="">2019</a>)</span>.</p>
</section></section>
<section>
<section id="conclusion-2" class="title-slide slide level1 center">
<h1>Conclusion</h1>

</section>
<section id="conclusion-3" class="slide level2">
<h2>Conclusion</h2>
<p>C’est un sujet difficile et/car computationnel, lire :</p>
<ul>
<li><span class="citation" data-cites="imbertVialaneix2018">Imbert and Vialaneix (<a href="#/références" role="doc-biblioref" onclick="">2018</a>)</span>, une biblio très fournie méthodo et implémentations.</li>
<li><a href="http://math.agrocampus-ouest.fr/infoglueDeliverLive/digitalAssets/105543_museum_hist_nat.pdf">Imputation multiple &amp; analyse factorielle, François Husson</a><sup>1</sup>.</li>
<li><a href="https://cran.r-project.org/web/packages/Amelia/vignettes/intro-mi.html">Utilisation d’Amelia II et imputation multiple</a><sup>2</sup></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn4"><p><a href="http://math.agrocampus-ouest.fr/infoglueDeliverLive/digitalAssets/105543_museum_hist_nat.pdf" class="uri">http://math.agrocampus-ouest.fr/infoglueDeliverLive/digitalAssets/105543_museum_hist_nat.pdf</a></p></li><li id="fn5"><p><a href="https://cran.r-project.org/web/packages/Amelia/vignettes/intro-mi.html" class="uri">https://cran.r-project.org/web/packages/Amelia/vignettes/intro-mi.html</a></p></li></ol></aside></section>
<section id="références" class="slide level2 allowframebreaks smaller scrollable">
<h2>Références</h2>
<div class="quarto-auto-generated-content">
<p><img src="amU.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-attias1999variational" class="csl-entry" role="listitem">
Attias, Hagai. 1999. <span>“A Variational Baysian Framework for Graphical Models.”</span> <em>Advances in Neural Information Processing Systems</em> 12.
</div>
<div id="ref-boothHobert1999" class="csl-entry" role="listitem">
Booth, J. G., and J. P. Hobert. 1999. <span>“Maximizing Generalized Linear Mixed Model Likelihoods with an Automated Monte Carlo EM Algorithm.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 61 (1): 265–85. https://doi.org/<a href="https://doi.org/10.1111/1467-9868.00176">https://doi.org/10.1111/1467-9868.00176</a>.
</div>
<div id="ref-dempster77" class="csl-entry" role="listitem">
Dempster, A. P., N. M. Laird, and D. B. Rubin. 1977. <span>“Maximum Likelihood from Incomplete Data via the EM Algorithm.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 39 (1): 1–22. https://doi.org/<a href="https://doi.org/10.1111/j.2517-6161.1977.tb01600.x">https://doi.org/10.1111/j.2517-6161.1977.tb01600.x</a>.
</div>
<div id="ref-HonKin10" class="csl-entry" role="listitem">
Honaker, James, and Gary King. 2010. <span>“What to Do about Missing Values in Time Series Cross-Section Data.”</span> <em>American Journal of Political Science</em> 54 (3): 561–81.
</div>
<div id="ref-imbertVialaneix2018" class="csl-entry" role="listitem">
Imbert, Alyssa, and Nathalie Vialaneix. 2018. <span>“<span class="nocase">D<span class="nocase">é</span>crire, prendre en compte, imputer et <span class="nocase">é</span>valuer les valeurs manquantes dans les <span class="nocase">é</span>tudes statistiques : une revue des approches existantes</span>.”</span> <em><span>Journal de La Societe Fran<span>ç</span>aise de Statistique</span></em> 159 (2): 1–55. <a href="https://hal.inrae.fr/hal-02618033">https://hal.inrae.fr/hal-02618033</a>.
</div>
<div id="ref-missmda" class="csl-entry" role="listitem">
Josse, Julie, and François Husson. 2016. <span>“<span class="nocase">missMDA</span>: A Package for Handling Missing Values in Multivariate Data Analysis.”</span> <em>Journal of Statistical Software</em> 70 (1): 1–31. <a href="https://doi.org/10.18637/jss.v070.i01">https://doi.org/10.18637/jss.v070.i01</a>.
</div>
<div id="ref-little2019statistical" class="csl-entry" role="listitem">
Little, Roderick JA, and Donald B Rubin. 1976. <em>Statistical Analysis with Missing Data</em>. Vol. 793. John Wiley &amp; Sons.
</div>
<div id="ref-lorenzo2019supervised" class="csl-entry" role="listitem">
LORENZO, Hadrien, Jérôme SARACCO, and Rodolphe THIÉBAUT. 2019. <span>“Supervised Learning for Multi-Block Incomplete Data.”</span> <em>arXiv Preprint arXiv:1901.04380</em>.
</div>
<div id="ref-neal1998view" class="csl-entry" role="listitem">
Neal, Radford M, and Geoffrey E Hinton. 1998. <span>“A View of the EM Algorithm That Justifies Incremental, Sparse, and Other Variants.”</span> In <em>Learning in Graphical Models</em>, 355–68. Springer.
</div>
<div id="ref-rechtien2017systems" class="csl-entry" role="listitem">
Rechtien, Anne, Laura Richert, Hadrien Lorenzo, Gloria Martrus, Boris Hejblum, Christine Dahlke, Rahel Kasonta, et al. 2017. <span>“Systems Vaccinology Identifies an Early Innate Immune Signature as a Correlate of Antibody Responses to the Ebola Vaccine rVSV-ZEBOV.”</span> <em>Cell Reports</em> 20 (9): 2251–61.
</div>
<div id="ref-mimi" class="csl-entry" role="listitem">
Stekhoven, Daniel J., and Peter Buehlmann. 2012. <span>“MissForest - Non-Parametric Missing Value Imputation for Mixed-Type Data.”</span> <em>Bioinformatics</em> 28 (1): 112–18.
</div>
<div id="ref-tannerwong1987" class="csl-entry" role="listitem">
Tanner, Martin A., and Wing Hung Wong. 1987. <span>“The Calculation of Posterior Distributions by Data Augmentation.”</span> <em>Journal of the American Statistical Association</em> 82 (398): 528–40.
</div>
<div id="ref-troyanskaya2001" class="csl-entry" role="listitem">
Troyanskaya, Olga, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor Hastie, Robert Tibshirani, David Botstein, and Russ B. Altman. 2001. <span>“<span class="nocase">Missing value estimation methods for DNA microarrays </span>.”</span> <em>Bioinformatics</em> 17 (6): 520–25.
</div>
<div id="ref-mice" class="csl-entry" role="listitem">
van Buuren, Stef, and Karin Groothuis-Oudshoorn. 2011. <span>“<span class="nocase">mice</span>: Multivariate Imputation by Chained Equations in r.”</span> <em>Journal of Statistical Software</em> 45 (3): 1–67. <a href="https://www.jstatsoft.org/v45/i03/">https://www.jstatsoft.org/v45/i03/</a>.
</div>
<div id="ref-weiTanner90" class="csl-entry" role="listitem">
Wei, Greg C. G., and Martin A. Tanner. 1990. <span>“A Monte Carlo Implementation of the EM Algorithm and the Poor Man’s Data Augmentation Algorithms.”</span> <em>Journal of the American Statistical Association</em> 85 (411): 699–704. <a href="https://doi.org/10.1080/01621459.1990.10474930">https://doi.org/10.1080/01621459.1990.10474930</a>.
</div>
</div>
</section></section>

    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="M2_stats_de_la_SD_2024_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>